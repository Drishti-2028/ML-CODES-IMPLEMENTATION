# -*- coding: utf-8 -*-
"""ML.IMPLEMENTATION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gCwcLrgPd_S2nEGj7SnlucgunBnQBnTI
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Dataset
X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)
y = np.array([2, 4, 6, 8, 10])

# Model
model = LinearRegression()
model.fit(X, y)

# Prediction
y_pred = model.predict(X)

print("Slope (m):", model.coef_[0])
print("Intercept (c):", model.intercept_)

# Plot
plt.scatter(X, y)
plt.plot(X, y_pred)
plt.xlabel("X")
plt.ylabel("y")
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Dataset
data = {
    "Area": [1000, 1500, 2000, 2500, 3000],
    "Bedrooms": [2, 3, 3, 4, 4],
    "Price": [200000, 300000, 400000, 500000, 600000]
}

df = pd.DataFrame(data)

X = df[["Area", "Bedrooms"]]
y = df["Price"]

# Model
model = LinearRegression()
model.fit(X, y)

# Prediction
y_pred = model.predict(X)

# Graph
plt.figure()
plt.scatter(y, y_pred)
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title("Multiple Linear Regression (Actual vs Predicted)")
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression

# Dataset
X = np.array([1, 2, 3, 4, 5, 6]).reshape(-1, 1)
y = np.array([0, 0, 0, 1, 1, 1])

# Model
model = LogisticRegression()
model.fit(X, y)

# Prediction curve
X_test = np.linspace(1, 6, 100).reshape(-1, 1)
y_prob = model.predict_proba(X_test)[:, 1]

# Graph
plt.figure()
plt.scatter(X, y)
plt.plot(X_test, y_prob)
plt.xlabel("X")
plt.ylabel("Probability")
plt.title("Logistic Regression")
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# =====================================
# LINEAR REGRESSION (GRAPH OUTPUT)
# =====================================

# Dataset
X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)
y = np.array([2, 4, 6, 8, 10])

# Model
lr = LinearRegression()
lr.fit(X, y)

# Prediction
y_pred = lr.predict(X)

# Graph
plt.figure()
plt.scatter(X, y)
plt.plot(X, y_pred)
plt.xlabel("X")
plt.ylabel("Y")
plt.title("Linear Regression")
plt.show()


# =====================================
# MULTIPLE LINEAR REGRESSION (GRAPH OUTPUT)
# Actual vs Predicted
# =====================================

# Dataset
data = {
    "Area": [1000, 1500, 2000, 2500, 3000],
    "Bedrooms": [2, 3, 3, 4, 4],
    "Price": [200000, 300000, 400000, 500000, 600000]
}

df = pd.DataFrame(data)

X_multi = df[["Area", "Bedrooms"]]
y_multi = df["Price"]

# Model
mlr = LinearRegression()
mlr.fit(X_multi, y_multi)

# Prediction
y_multi_pred = mlr.predict(X_multi)

# Graph
plt.figure()
plt.scatter(y_multi, y_multi_pred)
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title("Multiple Linear Regression (Actual vs Predicted)")
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier

# -------------------------------
# Step 1: Create Dataset
# -------------------------------
# Features (X) and labels (y)
X = np.array([
    [1, 2],
    [2, 3],
    [3, 3],
    [6, 5],
    [7, 7],
    [8, 6]
])

y = np.array([0, 0, 0, 1, 1, 1])  # Class labels

# -------------------------------
# Step 2: Create KNN Model
# -------------------------------
k = 3
knn = KNeighborsClassifier(n_neighbors=k)
knn.fit(X, y)

# -------------------------------
# Step 3: Predict New Point
# -------------------------------
new_point = np.array([[4, 4]])
prediction = knn.predict(new_point)

print("Predicted Class for", new_point, ":", prediction[0])

# -------------------------------
# Step 4: Plot Graph
# -------------------------------
plt.figure()

# Plot class 0
plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1])
# Plot class 1
plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1])

# Plot new point
plt.scatter(new_point[:, 0], new_point[:, 1], marker='x')

plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.title("KNN Classification (k = 3)")
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# -------------------------------
# Step 1: Dataset
# -------------------------------
X = np.array([1, 2, 3, 4, 5])
y = np.array([2, 4, 6, 8, 10])

# -------------------------------
# Step 2: Initialize parameters
# -------------------------------
m = 0.0   # slope
c = 0.0   # intercept
learning_rate = 0.01
epochs = 50
n = len(X)

# -------------------------------
# Step 3: Gradient Descent Loop
# -------------------------------
for _ in range(epochs):
    y_pred = m * X + c
    dm = (-2/n) * np.sum(X * (y - y_pred))
    dc = (-2/n) * np.sum(y - y_pred)
    m = m - learning_rate * dm
    c = c - learning_rate * dc

# -------------------------------
# Step 4: Final Prediction
# -------------------------------
final_y_pred = m * X + c

# -------------------------------
# Step 5: Graph Output
# -------------------------------
plt.figure()
plt.scatter(X, y)
plt.plot(X, final_y_pred)
plt.xlabel("X")
plt.ylabel("Y")
plt.title("Gradient Descent for Linear Regression")
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, plot_tree

# -------------------------------
# Step 1: Dataset (Encoded)
# -------------------------------
# Outlook: Sunny=0, Overcast=1, Rain=2
# Temperature: Hot=0, Mild=1, Cool=2
# Humidity: High=0, Normal=1
# Wind: Weak=0, Strong=1
# PlayTennis: No=0, Yes=1

data = {
    "Outlook": [0,0,1,2,2,2,1,0,0,2,0,1,1,2],
    "Temperature": [0,0,0,1,2,2,2,1,2,1,1,1,0,1],
    "Humidity": [0,0,0,0,1,1,1,0,1,1,1,0,1,0],
    "Wind": [0,1,0,0,0,1,1,0,0,0,1,1,0,1],
    "PlayTennis": [0,0,1,1,1,0,1,0,1,1,1,1,1,0]
}

df = pd.DataFrame(data)

X = df.drop("PlayTennis", axis=1)
y = df["PlayTennis"]

# -------------------------------
# Step 2: Train Decision Tree
# -------------------------------
model = DecisionTreeClassifier(criterion="gini")
model.fit(X, y)

# -------------------------------
# Step 3: Plot Decision Tree
# -------------------------------
plt.figure(figsize=(14, 8))
plot_tree(
    model,
    feature_names=X.columns,
    class_names=["No", "Yes"],
    filled=True
)
plt.title("Decision Tree Classifier")
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier

# -------------------------------
# Step 1: Dataset
# -------------------------------
X = np.array([
    [1, 2],
    [2, 3],
    [3, 3],
    [6, 5],
    [7, 7],
    [8, 6]
])

y = np.array([0, 0, 0, 1, 1, 1])

# Create mesh grid
xx, yy = np.meshgrid(
    np.linspace(0, 9, 200),
    np.linspace(0, 9, 200)
)

# -------------------------------
# Step 2: Decision Tree
# -------------------------------
dt = DecisionTreeClassifier(criterion="gini")
dt.fit(X, y)

Z_dt = dt.predict(np.c_[xx.ravel(), yy.ravel()])
Z_dt = Z_dt.reshape(xx.shape)

plt.figure()
plt.contourf(xx, yy, Z_dt, alpha=0.3)
plt.scatter(X[:, 0], X[:, 1], c=y)
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.title("Decision Tree Classification")
plt.show()

# -------------------------------
# Step 3: KNN
# -------------------------------
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X, y)

Z_knn = knn.predict(np.c_[xx.ravel(), yy.ravel()])
Z_knn = Z_knn.reshape(xx.shape)

plt.figure()
plt.contourf(xx, yy, Z_knn, alpha=0.3)
plt.scatter(X[:, 0], X[:, 1], c=y)
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.title("KNN Classification (k = 3)")
plt.show()